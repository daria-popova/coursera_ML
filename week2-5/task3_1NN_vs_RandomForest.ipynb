{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание по программированию: 1NN против RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании будет использоваться датасет **digits** из **sklearn.datasets**. Оставьте последние **25%** объектов для контроля качества, разделив X и y на **X_train, y_train и X_test, y_test**.\n",
    "\n",
    "Целью задания будет реализовать самый простой метрический классификатор — метод ближайшего соседа, а также сравнить качество работы реализованного вами **1NN** с **RandomForestClassifier** из sklearn на **1000 деревьях**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1\n",
    "\n",
    "Реализуйте самостоятельно **метод одного ближайшего соседа с евклидовой метрикой для задачи классификации**. Можно не извлекать корень из суммы квадратов отклонений, т.к. корень — монотонное преобразование и не влияет на результат работы алгоритма.  \n",
    "\n",
    "Никакой дополнительной работы с признаками в этом задании делать не нужно — мы еще успеем этим заняться в других курсах. Ваша реализация может быть устроена следующим образом: **можно для каждого классифицируемого объекта составлять список пар (расстояние до точки из обучающей выборки, метка класса в этой точке), затем сортировать этот список (по умолчанию сортировка будет сначала по первому элементу пары, затем по второму), а затем брать первый элемент (с наименьшим расстоянием)**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, model_selection, metrics\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "data = datasets.load_digits()\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data.data, data.target, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = [0,0,0]\n",
    "#b = [2,2,2]\n",
    "#print(sum([(a[0]- a[1])**2 for a in zip(a,b)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 s, sys: 0 ns, total: 35.7 s\n",
      "Wall time: 35.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_predicted = np.zeros(len(X_test))\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    min_index = -1 \n",
    "    min_dist = float('inf') \n",
    "    for j in range(len(X_train)):\n",
    "        dist = sum([(a[0]- a[1])**2 for a in zip(X_test[i],X_train[j])])\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            min_index = j\n",
    "            \n",
    "    y_predicted[i] = y_train[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.9911111111111112\n",
      "error rate 0.008888888888888889\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score = accuracy_score(y_predicted, y_test)\n",
    "print(\"accuracy_score\", score)\n",
    "\n",
    "\n",
    "errors_cnt = len(list(filter(lambda a: a[0] != a[1] , zip(y_predicted, y_test))))\n",
    "print(\"error rate\", errors_cnt / len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сортировка массива длиной N требует порядка **N log N** сравнений (строже говоря, она работает за **O(N log N))**. **Подумайте, как можно легко улучшить получившееся время работы**.   \n",
    "\n",
    "Кроме простого способа найти ближайший объект всего за N сравнений, можно попробовать придумать, как разбить пространство признаков на части и сделать структуру данных, которая позволит быстро искать соседей каждой точки. За выбор метода поиска ближайших соседей в KNeighborsClassifier из sklearn отвечает параметр algorithm — если у вас уже есть некоторый бэкграунд в алгоритмах и структурах данных, вам может быть интересно познакомиться **со структурами данных ball tree и kd tree.**\n",
    "\n",
    "**Доля ошибок, допускаемых 1NN на тестовой выборке, — ответ в задании 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2\n",
    "\n",
    "Теперь обучите на обучающей выборке **RandomForestClassifier(n_estimators=1000)** из sklearn.   \n",
    "\n",
    "Сделайте прогнозы на тестовой выборке и оцените долю ошибок классификации на ней.   \n",
    "\n",
    "**Эта доля — ответ в задании 2.**\n",
    "\n",
    "\n",
    "Обратите внимание на то, как соотносится качество работы случайного леса с качеством работы, пожалуй, одного из самых простых методов — 1NN. \n",
    "\n",
    "Такое различие — особенность данного датасета, но нужно всегда помнить, что такая ситуация тоже может иметь место, и не забывать про простые методы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble, model_selection, metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.84 s, sys: 7.99 ms, total: 2.85 s\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf_classifier = ensemble.RandomForestClassifier(n_estimators = 1000, random_state = 1)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_predicted_rf = rf_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score 0.98\n",
      "error rate 0.02\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_predicted_rf, y_test)\n",
    "print(\"accuracy_score\", score)\n",
    "\n",
    "errors_cnt = len(list(filter(lambda a: a[0] != a[1] , zip(y_predicted_rf, y_test))))\n",
    "print(\"error rate\", errors_cnt / len(y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
